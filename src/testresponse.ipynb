{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6a21833-5d66-45d0-b82c-2775d4b6948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://llama_server:8080/completion\"\n",
    "data = {\n",
    "    \"prompt\":\"Write a limmerick about APIs\",\n",
    "    \"max token\": 100,\n",
    "    \"temperature\":0.6\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "api_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f4d1a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI've got a secret to share,\\nIt's not in a file or a folder,\\nBut in the cloud,\\nIt's still allowed,\\nTo call it, just use an API.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f471c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://llama_server:8080/embedding\"\n",
    "data = {\n",
    "    \"input\":\"Write a limmerick about APIs\",\n",
    "    \"thread\": 5,\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "api_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b0da110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008568997494876385,\n",
       " -0.00866398960351944,\n",
       " 0.011883268132805824,\n",
       " 0.002075440948829055,\n",
       " -0.012170018628239632,\n",
       " 0.000959977856837213,\n",
       " -0.015333020128309727,\n",
       " 0.007431202568113804,\n",
       " -0.00624220771715045,\n",
       " 0.0012937940191477537,\n",
       " -0.0004488003032747656,\n",
       " -0.011214075610041618,\n",
       " -0.0014655513223260641,\n",
       " -0.010296683758497238,\n",
       " -0.0035408579278737307,\n",
       " 0.021859781816601753,\n",
       " 0.01042693480849266,\n",
       " 0.00023671897361055017,\n",
       " 0.0012043850729241967,\n",
       " 0.008268057368695736,\n",
       " -0.005498598795384169,\n",
       " -0.005060725845396519,\n",
       " 0.003574532689526677,\n",
       " 0.01971864514052868,\n",
       " -0.00676048593595624,\n",
       " -0.001474608201533556,\n",
       " 0.0027081496082246304,\n",
       " 0.001054530730471015,\n",
       " -0.0047048707492649555,\n",
       " -0.01119994092732668,\n",
       " 0.0005658998270519078,\n",
       " -0.002485707402229309,\n",
       " 0.011359469965100288,\n",
       " -0.0036545302718877792,\n",
       " 0.011416800320148468,\n",
       " -0.018520090728998184,\n",
       " -0.0038961218670010567,\n",
       " 0.0010900853667408228,\n",
       " -0.005692352540791035,\n",
       " 0.006781651172786951,\n",
       " -0.002703373786062002,\n",
       " 0.006698273587971926,\n",
       " 0.0019681984558701515,\n",
       " 0.011011072434484959,\n",
       " 0.010250481776893139,\n",
       " -0.007168913725763559,\n",
       " 0.004276824649423361,\n",
       " 0.0057055093348026276,\n",
       " 0.0029706708155572414,\n",
       " 0.0024904096499085426,\n",
       " 0.007452602032572031,\n",
       " -0.039927151054143906,\n",
       " -0.012659880332648754,\n",
       " 0.014218596741557121,\n",
       " 0.022637486457824707,\n",
       " -0.005555801093578339,\n",
       " -0.001174408127553761,\n",
       " -0.0038558696396648884,\n",
       " -0.006607057061046362,\n",
       " -0.006177220027893782,\n",
       " -0.0040215495973825455,\n",
       " 0.03071129135787487,\n",
       " -0.007110245060175657,\n",
       " 0.006492245942354202,\n",
       " -0.008443014696240425,\n",
       " -0.014685418456792831,\n",
       " 0.006989616435021162,\n",
       " 0.0070525240153074265,\n",
       " 0.006225787103176117,\n",
       " -0.011917592957615852,\n",
       " -0.00262824771925807,\n",
       " 0.012501783668994904,\n",
       " 0.005709155462682247,\n",
       " 0.007472079247236252,\n",
       " -0.007879966869950294,\n",
       " -0.012185033410787582,\n",
       " -0.001854484318755567,\n",
       " -0.006587793584913015,\n",
       " -0.0034537985920906067,\n",
       " -0.013075943104922771,\n",
       " -0.0012826580787077546,\n",
       " -0.02173629403114319,\n",
       " -0.0076553369872272015,\n",
       " -0.004568461794406176,\n",
       " 0.0011403922690078616,\n",
       " 0.00557850394397974,\n",
       " -0.0029910223092883825,\n",
       " -0.00514661381021142,\n",
       " -0.01707877404987812,\n",
       " 0.005482844542711973,\n",
       " -0.0019113325979560614,\n",
       " -0.0033459430560469627,\n",
       " 0.006673208903521299,\n",
       " 0.006978337187319994,\n",
       " -0.0009783789282664657,\n",
       " 0.00019061475177295506,\n",
       " -0.00012447239714674652,\n",
       " -0.009223331697285175,\n",
       " 0.010837751440703869,\n",
       " -0.005256411153823137,\n",
       " 0.004740134812891483,\n",
       " 0.004086368251591921,\n",
       " -0.014995112083852291,\n",
       " -0.010991289280354977,\n",
       " 0.018095098435878754,\n",
       " -0.0028434214182198048,\n",
       " 0.0001556998904561624,\n",
       " 0.0021986598148941994,\n",
       " 0.009033869951963425,\n",
       " 0.007658150512725115,\n",
       " -0.006248957943171263,\n",
       " 0.002320524537935853,\n",
       " 0.000765621371101588,\n",
       " -0.017211096361279488,\n",
       " -0.01502115000039339,\n",
       " 0.004671642556786537,\n",
       " -0.001773316878825426,\n",
       " 0.007918035611510277,\n",
       " 0.0034294966608285904,\n",
       " 0.0041075218468904495,\n",
       " 0.00026000748039223254,\n",
       " 0.005665279924869537,\n",
       " -0.010519200004637241,\n",
       " -0.005037541501224041,\n",
       " -0.004505627788603306,\n",
       " 0.0015942530008032918,\n",
       " -0.008796503767371178,\n",
       " -0.011531337164342403,\n",
       " -0.007183869369328022,\n",
       " 0.004000528249889612,\n",
       " -0.0018957292195409536,\n",
       " 0.001596701331436634,\n",
       " 0.00046338734682649374,\n",
       " -0.0013997744536027312,\n",
       " -0.005778265185654163,\n",
       " 0.001965384930372238,\n",
       " -0.0025327494367957115,\n",
       " -0.006635538302361965,\n",
       " -0.0007118835346773267,\n",
       " -0.002921810606494546,\n",
       " -0.008218465372920036,\n",
       " 0.015896769240498543,\n",
       " -0.10592980682849884,\n",
       " -0.003154648467898369,\n",
       " -0.012797832489013672,\n",
       " -0.01086993794888258,\n",
       " -0.0032412190921604633,\n",
       " -0.0025402831379324198,\n",
       " 0.0028122002258896828,\n",
       " -0.002478792332112789,\n",
       " 0.010922516696155071,\n",
       " 0.0006264829426072538,\n",
       " 0.003201413666829467,\n",
       " 0.002501267706975341,\n",
       " -0.00399093609303236,\n",
       " -0.0008217876893468201,\n",
       " -0.0028329179622232914,\n",
       " 0.00741642527282238,\n",
       " 0.008911610580980778,\n",
       " -0.0004265457973815501,\n",
       " -0.014710376970469952,\n",
       " -0.0013758742716163397,\n",
       " 0.007782322354614735,\n",
       " 0.004796813242137432,\n",
       " -0.003131372155621648,\n",
       " -0.007562681566923857,\n",
       " -0.006363376043736935,\n",
       " -0.005839762277901173,\n",
       " 0.008799048140645027,\n",
       " 0.007443206384778023,\n",
       " 0.001440267893485725,\n",
       " 0.01136506162583828,\n",
       " 0.008588134311139584,\n",
       " 0.005833933129906654,\n",
       " -0.009822388179600239,\n",
       " 0.0044708591885864735,\n",
       " -0.004848530050367117,\n",
       " -0.0020407489500939846,\n",
       " -0.0033629341050982475,\n",
       " -0.0035278471186757088,\n",
       " 0.006603498011827469,\n",
       " 0.012082086876034737,\n",
       " -0.0077146808616817,\n",
       " 0.014643346890807152,\n",
       " -0.008161562494933605,\n",
       " -0.0031289064791053534,\n",
       " -0.002183635486289859,\n",
       " -0.0020774235017597675,\n",
       " 0.0016117241466417909,\n",
       " 0.0015326805878430605,\n",
       " 0.0053842682391405106,\n",
       " 0.010507914237678051,\n",
       " 0.005160938948392868,\n",
       " 0.0026828257832676172,\n",
       " 0.013000738807022572,\n",
       " 0.0017387521220371127,\n",
       " -0.00797423254698515,\n",
       " 0.008668492548167706,\n",
       " 0.012692781165242195,\n",
       " -0.0022392887622117996,\n",
       " -0.001348479650914669,\n",
       " 0.004269715398550034,\n",
       " 0.013521052896976471,\n",
       " 0.010000437498092651,\n",
       " 0.004389180336147547,\n",
       " 0.00412806635722518,\n",
       " 0.006349211558699608,\n",
       " -0.01192789152264595,\n",
       " -0.0008812171872705221,\n",
       " -0.018488071858882904,\n",
       " 0.00393076753243804,\n",
       " 0.0008569768979214132,\n",
       " 0.009215346537530422,\n",
       " -0.008678065612912178,\n",
       " 0.0028349696658551693,\n",
       " -0.00914381816983223,\n",
       " -0.003911652602255344,\n",
       " -0.00015613599680364132,\n",
       " -0.006083189509809017,\n",
       " -0.005503674503415823,\n",
       " 0.01380910910665989,\n",
       " -0.01062644924968481,\n",
       " -0.007866275496780872,\n",
       " 0.006041133776307106,\n",
       " 0.0019880272448062897,\n",
       " -0.002152759116142988,\n",
       " 0.008255437947809696,\n",
       " -0.004169129766523838,\n",
       " -0.015124033205211163,\n",
       " -0.0032222021836787462,\n",
       " -0.0007683550356887281,\n",
       " -0.0013758509885519743,\n",
       " -0.009182500652968884,\n",
       " -0.02004646509885788,\n",
       " 0.0017433016328141093,\n",
       " 0.003025198355317116,\n",
       " 0.004717683885246515,\n",
       " 0.006131675094366074,\n",
       " -0.004744227044284344,\n",
       " 0.008695793338119984,\n",
       " -0.006979490164667368,\n",
       " 0.008171368390321732,\n",
       " -0.0003585278464015573,\n",
       " 0.036552075296640396,\n",
       " 6.063376349629834e-05,\n",
       " -0.006325245834887028,\n",
       " 0.014614084735512733,\n",
       " -0.007309112697839737,\n",
       " 0.003582917619496584,\n",
       " 0.006021272391080856,\n",
       " 0.0010281173745170236,\n",
       " -0.007728605531156063,\n",
       " -0.005529876332730055,\n",
       " -0.012191238813102245,\n",
       " 0.0035903414245694876,\n",
       " -0.003229959402233362,\n",
       " -0.005269848741590977,\n",
       " -0.004064609762281179,\n",
       " 0.001252032001502812,\n",
       " 0.00752596091479063,\n",
       " -0.051522523164749146,\n",
       " 0.010916830971837044,\n",
       " -0.0003501883475109935,\n",
       " 0.00387009559199214,\n",
       " 0.017726775258779526,\n",
       " 0.027399204671382904,\n",
       " -0.1111818328499794,\n",
       " 0.009412542916834354,\n",
       " -0.007463100831955671,\n",
       " -0.013388128951191902,\n",
       " -0.004097281489521265,\n",
       " 0.0011555356904864311,\n",
       " 0.015046236105263233,\n",
       " -0.0068251523189246655,\n",
       " 0.004497287329286337,\n",
       " 0.004065076820552349,\n",
       " 0.0034331928472965956,\n",
       " -0.00038469451828859746,\n",
       " 0.005771370138972998,\n",
       " -0.004938418511301279,\n",
       " 0.0015360981924459338,\n",
       " 0.0019725016318261623,\n",
       " 0.00675938930362463,\n",
       " 0.0026844278909265995,\n",
       " -0.010422248393297195,\n",
       " 0.010411371476948261,\n",
       " 0.0006925637717358768,\n",
       " -0.01676945574581623,\n",
       " 0.0005756306927651167,\n",
       " -0.003594179404899478,\n",
       " -0.0013808358926326036,\n",
       " -0.004357651807367802,\n",
       " 0.00045340831275098026,\n",
       " 0.00563020259141922,\n",
       " -0.003592024091631174,\n",
       " 0.024515602737665176,\n",
       " -0.006328299175947905,\n",
       " 0.003468964947387576,\n",
       " -0.016477249562740326,\n",
       " -0.004679997451603413,\n",
       " 0.007728331256657839,\n",
       " 0.00752944964915514,\n",
       " -0.003450204851105809,\n",
       " -0.001692646648734808,\n",
       " -0.0018163586501032114,\n",
       " -0.009246611967682838,\n",
       " 0.002330718096345663,\n",
       " -0.003139752894639969,\n",
       " -0.005665359552949667,\n",
       " -0.006682476960122585,\n",
       " -0.001310818362981081,\n",
       " -0.006690929178148508,\n",
       " -0.0012888300698250532,\n",
       " -0.00830275472253561,\n",
       " -0.011568799614906311,\n",
       " 0.002752679167315364,\n",
       " -0.003566454164683819,\n",
       " -0.010456668213009834,\n",
       " 0.001481741084717214,\n",
       " 0.0009362467681057751,\n",
       " 0.025643404573202133,\n",
       " -0.005428913049399853,\n",
       " 0.01326863095164299,\n",
       " -0.014598578214645386,\n",
       " -0.000831554236356169,\n",
       " -0.0005999239510856569,\n",
       " -0.007391198538243771,\n",
       " 0.0027904382441192865,\n",
       " 0.0026964887510985136,\n",
       " 0.00514483917504549,\n",
       " 0.004033457022160292,\n",
       " 0.010561699979007244,\n",
       " -0.006428783293813467,\n",
       " 4.3981453927699476e-05,\n",
       " -0.001095163868740201,\n",
       " -0.009553281590342522,\n",
       " -0.0045956713147461414,\n",
       " -0.01666267402470112,\n",
       " -0.0022123982198536396,\n",
       " 0.0024887211620807648,\n",
       " 0.006409874651581049,\n",
       " 0.0043243826366961,\n",
       " 0.0013309745118021965,\n",
       " -0.0005774871096946299,\n",
       " -0.012536847032606602,\n",
       " 0.0005246153450571001,\n",
       " 0.006616571452468634,\n",
       " 0.006107148714363575,\n",
       " 0.007476718630641699,\n",
       " -0.006545290816575289,\n",
       " -0.0017609249334782362,\n",
       " -0.0012542452896013856,\n",
       " 0.012635172344744205,\n",
       " 0.003794977441430092,\n",
       " 0.05864856764674187,\n",
       " 0.003089859848842025,\n",
       " -0.0008199645089916885,\n",
       " -0.02139822207391262,\n",
       " -0.0048342542722821236,\n",
       " 0.00471431203186512,\n",
       " 0.008648418821394444,\n",
       " 0.0018104452174156904,\n",
       " -0.006578249856829643,\n",
       " -0.000642202387098223,\n",
       " -0.004324329551309347,\n",
       " -0.015589684247970581,\n",
       " -0.01689491607248783,\n",
       " -0.011319100856781006,\n",
       " 0.0022855582647025585,\n",
       " -0.0018765211571007967,\n",
       " -0.0001628362515475601,\n",
       " 0.001613349188119173,\n",
       " 0.004690214060246944,\n",
       " 0.018262049183249474,\n",
       " -0.009794013574719429,\n",
       " 0.009313918650150299,\n",
       " 0.009618737734854221,\n",
       " -0.00904825609177351,\n",
       " 0.020001590251922607,\n",
       " -0.005491530057042837,\n",
       " -0.004392324946820736,\n",
       " -0.011199097149074078,\n",
       " -0.006373313721269369,\n",
       " -0.014203999191522598,\n",
       " -0.004726971033960581,\n",
       " -0.0030531182419508696,\n",
       " 0.0017989070620387793,\n",
       " -0.011757779866456985,\n",
       " -0.011907008476555347,\n",
       " 0.0008004983537830412,\n",
       " 0.0038923725951462984,\n",
       " -0.0025469197425991297,\n",
       " 0.00022821557649876922,\n",
       " -0.010599512606859207,\n",
       " 0.024081815034151077,\n",
       " -0.007728768512606621,\n",
       " 0.01099502295255661,\n",
       " 0.013435299508273602,\n",
       " -0.013011325150728226,\n",
       " 0.010643422603607178,\n",
       " 0.003119192086160183,\n",
       " 0.002185126068070531,\n",
       " 0.0029276516288518906,\n",
       " 0.00023523251002188772,\n",
       " 0.0013616501819342375,\n",
       " -0.011893314309418201,\n",
       " 0.020509321242570877,\n",
       " 0.0504603311419487,\n",
       " -0.005813429597765207,\n",
       " -0.01836634799838066,\n",
       " 0.01351493876427412,\n",
       " -0.001508874585852027,\n",
       " 0.011233093217015266,\n",
       " -0.01321015041321516,\n",
       " -0.00882980227470398,\n",
       " 0.0037881715688854456,\n",
       " -0.004960884805768728,\n",
       " -0.021663788706064224,\n",
       " -0.010984040796756744,\n",
       " 0.0005066815647296607,\n",
       " -0.002837354550138116,\n",
       " -0.0017647244967520237,\n",
       " -0.0011675816494971514,\n",
       " 0.0024440931156277657,\n",
       " 0.003692080033943057,\n",
       " -0.01784321293234825,\n",
       " -0.011850964277982712,\n",
       " -0.01574094593524933,\n",
       " 0.003119052853435278,\n",
       " 0.003897106507793069,\n",
       " -0.010207056999206543,\n",
       " 0.00039596224087290466,\n",
       " 0.018916109576821327,\n",
       " 0.008870566263794899,\n",
       " -0.001017137197777629,\n",
       " 0.014553708024322987,\n",
       " -0.015022085048258305,\n",
       " -0.005629466846585274,\n",
       " -0.01221461035311222,\n",
       " -0.018170299008488655,\n",
       " -0.0066172294318675995,\n",
       " 0.010602578520774841,\n",
       " 0.009006474167108536,\n",
       " 0.012117949314415455,\n",
       " -0.0018531923415139318,\n",
       " 0.0013308117631822824,\n",
       " -0.03909789398312569,\n",
       " -0.012820345349609852,\n",
       " 0.0065337070263922215,\n",
       " 0.004544887226074934,\n",
       " 0.014364507980644703,\n",
       " -0.010285829193890095,\n",
       " 0.010572826489806175,\n",
       " -0.012208004482090473,\n",
       " 0.0006120788748376071,\n",
       " 0.0140026044100523,\n",
       " 0.00266090570949018,\n",
       " -0.023274807259440422,\n",
       " -0.00922632310539484,\n",
       " -0.001143181580118835,\n",
       " 0.007574032060801983,\n",
       " 0.004094589035958052,\n",
       " -0.009347700513899326,\n",
       " -0.0060823517851531506,\n",
       " -0.0004645974258892238,\n",
       " 0.013065163977444172,\n",
       " 0.0069901468232274055,\n",
       " 0.007791794370859861,\n",
       " 0.00864894688129425,\n",
       " 0.014569203369319439,\n",
       " 0.013923091813921928,\n",
       " 0.00618697889149189,\n",
       " 0.0080342348664999,\n",
       " -0.014258925803005695,\n",
       " -0.005082621704787016,\n",
       " 0.011707042343914509,\n",
       " -0.005373197142034769,\n",
       " -0.007628981024026871,\n",
       " -0.009597260504961014,\n",
       " -0.007679547183215618,\n",
       " -0.00020382623188197613,\n",
       " -0.001884970348328352,\n",
       " 0.0012942412868142128,\n",
       " -0.0002103597071254626,\n",
       " 0.0016667454037815332,\n",
       " -0.011139977723360062,\n",
       " -0.0061752707697451115,\n",
       " 0.016718966886401176,\n",
       " 0.004032230470329523,\n",
       " 0.011162678711116314,\n",
       " -0.024219481274485588,\n",
       " 0.010724049061536789,\n",
       " 0.0011337293544784188,\n",
       " -0.011715227738022804,\n",
       " 0.01405204925686121,\n",
       " 0.009216809645295143,\n",
       " 0.002955501200631261,\n",
       " -0.01625179499387741,\n",
       " -0.010421708226203918,\n",
       " 0.009577698074281216,\n",
       " -0.007549823261797428,\n",
       " -0.0042877038940787315,\n",
       " -0.006349928677082062,\n",
       " 0.012324407696723938,\n",
       " -0.0014491755282506347,\n",
       " 0.0024995452258735895,\n",
       " 0.004065554589033127,\n",
       " -0.0004165361460763961,\n",
       " 0.003892505308613181,\n",
       " 0.0023312538396567106,\n",
       " 0.0055482396855950356,\n",
       " 0.004144582897424698,\n",
       " -0.01640966720879078,\n",
       " -0.0010473101865500212,\n",
       " -0.00606684060767293,\n",
       " 0.0027423687279224396,\n",
       " -0.006676330231130123,\n",
       " 0.01420545857399702,\n",
       " -0.007731005549430847,\n",
       " 0.006745642516762018,\n",
       " 0.0005517427925951779,\n",
       " 0.0032208978664129972,\n",
       " 0.00014582520816475153,\n",
       " -0.014904720708727837,\n",
       " -0.006379798986017704,\n",
       " 0.008549926802515984,\n",
       " -0.011691122315824032,\n",
       " -0.0008365442045032978,\n",
       " -0.007236921694129705,\n",
       " 0.010329592041671276,\n",
       " 0.0013364767655730247,\n",
       " 0.002914806129410863,\n",
       " -0.012987927533686161,\n",
       " -0.0011755615705624223,\n",
       " 0.012992103584110737,\n",
       " 0.009495188482105732,\n",
       " 0.002805215073749423,\n",
       " -0.00035468037822283804,\n",
       " -0.0021092609968036413,\n",
       " 0.002630910137668252,\n",
       " -0.004507944453507662,\n",
       " -0.011576525866985321,\n",
       " 0.0011712807463482022,\n",
       " -0.009968089871108532,\n",
       " -0.020318981260061264,\n",
       " 0.0024102020543068647,\n",
       " 0.006823529023677111,\n",
       " 0.0012536679860204458,\n",
       " 0.005708217155188322,\n",
       " -0.017523974180221558,\n",
       " -0.010770587250590324,\n",
       " -0.0069460198283195496,\n",
       " -0.0030798425432294607,\n",
       " -0.0013059754855930805,\n",
       " 0.00872214138507843,\n",
       " -0.008686388842761517,\n",
       " -0.014380990527570248,\n",
       " 0.012042607180774212,\n",
       " -0.007056600879877806,\n",
       " 0.005162129644304514,\n",
       " 0.009670007973909378,\n",
       " -0.005942488554865122,\n",
       " -0.003190981922671199,\n",
       " -0.0027948704082518816,\n",
       " 0.003787489142268896,\n",
       " -0.0010804187040776014,\n",
       " 0.014117778278887272,\n",
       " -0.004594775382429361,\n",
       " -0.001244234386831522,\n",
       " -0.004845654126256704,\n",
       " -0.027060149237513542,\n",
       " 0.008583853021264076,\n",
       " -0.004427055362612009,\n",
       " 0.003246203763410449,\n",
       " 0.00413454370573163,\n",
       " 0.00943444762378931,\n",
       " 0.006132958922535181,\n",
       " 0.0008707112283445895,\n",
       " -0.00026291064568795264,\n",
       " 0.015104163438081741,\n",
       " -0.003355784108862281,\n",
       " 0.005639872048050165,\n",
       " -0.002050630049780011,\n",
       " 0.006612176075577736,\n",
       " 0.0005358384223654866,\n",
       " 0.005358865950256586,\n",
       " 0.0024354930501431227,\n",
       " 0.0022908977698534727,\n",
       " -0.0013544021639972925,\n",
       " 0.00937986746430397,\n",
       " 0.0029272264800965786,\n",
       " 0.005297604016959667,\n",
       " 0.0007685120799578726,\n",
       " -0.008300035260617733,\n",
       " -0.009874765761196613,\n",
       " 0.0010725022293627262,\n",
       " -0.010370291769504547,\n",
       " -0.006669552531093359,\n",
       " -0.0016484305961057544,\n",
       " 0.006250725127756596,\n",
       " -0.011015979573130608,\n",
       " -0.007588978391140699,\n",
       " -0.00013338545977603644,\n",
       " -0.010163119994103909,\n",
       " 0.009192634373903275,\n",
       " -0.006486724130809307,\n",
       " -0.010287027806043625,\n",
       " -0.013753658160567284,\n",
       " -0.0007053941371850669,\n",
       " -0.015089928172528744,\n",
       " 0.015789052471518517,\n",
       " 0.00912201777100563,\n",
       " 0.007008010521531105,\n",
       " -0.00861800741404295,\n",
       " 0.007147323805838823,\n",
       " 0.016202567145228386,\n",
       " 0.010001292452216148,\n",
       " 0.0038284261245280504,\n",
       " 0.011792223900556564,\n",
       " 0.0014997164253145456,\n",
       " 0.002967060776427388,\n",
       " 0.004175994079560041,\n",
       " -0.003946258220821619,\n",
       " 0.009056027047336102,\n",
       " -0.0013438703026622534,\n",
       " 0.010066140443086624,\n",
       " -0.01309435535222292,\n",
       " 0.009849338792264462,\n",
       " -0.002750501036643982,\n",
       " -0.001218829769641161,\n",
       " -0.006409032735973597,\n",
       " -0.0024525215849280357,\n",
       " -0.007446132600307465,\n",
       " -0.013255948200821877,\n",
       " 0.013168000616133213,\n",
       " -0.007513876538723707,\n",
       " -0.004203720949590206,\n",
       " 0.0038630797062069178,\n",
       " -0.008735710754990578,\n",
       " -0.007140801288187504,\n",
       " 0.10622356086969376,\n",
       " -0.0019854216370731592,\n",
       " 0.0022160799708217382,\n",
       " -0.015243005938827991,\n",
       " -0.006980688311159611,\n",
       " -0.014171519316732883,\n",
       " -0.00816104281693697,\n",
       " 0.0013122933451086283,\n",
       " -0.004812320228666067,\n",
       " -0.011346271261572838,\n",
       " -0.017777489498257637,\n",
       " -0.016268784180283546,\n",
       " 0.001875844318419695,\n",
       " 0.003304715733975172,\n",
       " 0.0018603387288749218,\n",
       " -0.007195003796368837,\n",
       " 0.0013484929222613573,\n",
       " 0.022535137832164764,\n",
       " 0.002257698215544224,\n",
       " 0.001890717539936304,\n",
       " -0.0006715136114507914,\n",
       " 0.005358670372515917,\n",
       " -0.025372209027409554,\n",
       " -0.012363400310277939,\n",
       " -0.0013823166955262423,\n",
       " 0.006098776590079069,\n",
       " 0.020737767219543457,\n",
       " 0.007612052373588085,\n",
       " 0.0049326131120324135,\n",
       " 0.0009407863253727555,\n",
       " 0.0017095472430810332,\n",
       " -0.002808612072840333,\n",
       " 0.014309367164969444,\n",
       " 0.006236567627638578,\n",
       " 0.0015974160050973296,\n",
       " 0.0035855374298989773,\n",
       " 0.002460433403030038,\n",
       " 0.004590275697410107,\n",
       " 0.016044266521930695,\n",
       " 0.0340794175863266,\n",
       " 0.009374708868563175,\n",
       " -0.03325412794947624,\n",
       " 0.007062670309096575,\n",
       " -0.0014770134584978223,\n",
       " 0.0012691756710410118,\n",
       " 0.007694356609135866,\n",
       " 0.0014632465317845345,\n",
       " 0.014338533394038677,\n",
       " 0.004708683583885431,\n",
       " -0.025681227445602417,\n",
       " -0.003975235391408205,\n",
       " 0.025462867692112923,\n",
       " -1.2372764103929512e-05,\n",
       " -0.004842264112085104,\n",
       " 0.0032548028975725174,\n",
       " 0.006509498227387667,\n",
       " -0.0014934784267097712,\n",
       " -0.002071909373626113,\n",
       " 0.0037668708246201277,\n",
       " -0.00880497694015503,\n",
       " -0.0052085332572460175,\n",
       " 0.003932982217520475,\n",
       " 0.006367955822497606,\n",
       " -0.007354713510721922,\n",
       " 0.0018823997816070914,\n",
       " 0.002783849136903882,\n",
       " 0.0024940576404333115,\n",
       " 0.004626039881259203,\n",
       " -0.01533525437116623,\n",
       " -0.011685947887599468,\n",
       " 0.003981130663305521,\n",
       " 0.003559855977073312,\n",
       " -0.024613412097096443,\n",
       " 0.00558339711278677,\n",
       " 0.00711189117282629,\n",
       " -0.0008100265404209495,\n",
       " 0.002834233921021223,\n",
       " -0.007422080263495445,\n",
       " 0.0052458192221820354,\n",
       " -0.005450572818517685,\n",
       " -0.004314966034144163,\n",
       " -0.005779349245131016,\n",
       " -0.0024354709312319756,\n",
       " -0.00402872497215867,\n",
       " 0.006375571247190237,\n",
       " 0.0037879333831369877,\n",
       " -0.010967315174639225,\n",
       " 0.0015341457910835743,\n",
       " -0.0003924200136680156,\n",
       " 0.01857522688806057,\n",
       " -0.007947026751935482,\n",
       " 0.004101007245481014,\n",
       " -0.000905086169950664,\n",
       " -0.004247147124260664,\n",
       " 0.000374108727555722,\n",
       " -0.0042076632380485535,\n",
       " 0.00710008479654789,\n",
       " 0.010381835512816906,\n",
       " -0.0019158902578055859,\n",
       " -0.012367166578769684,\n",
       " -0.004517532419413328,\n",
       " 0.006349950563162565,\n",
       " 0.007047407794743776,\n",
       " -0.005144721362739801,\n",
       " 0.010733685456216335,\n",
       " 0.0028335354290902615,\n",
       " -0.00966374110430479,\n",
       " -0.004119198303669691,\n",
       " -0.006708193104714155,\n",
       " 0.0033590083476155996,\n",
       " -0.00785064697265625,\n",
       " -0.011247108690440655,\n",
       " 0.006945115048438311,\n",
       " -3.1175270123640075e-05,\n",
       " -0.006724977865815163,\n",
       " -0.0017705480568110943,\n",
       " -0.0024182675406336784,\n",
       " 0.009557613171637058,\n",
       " -0.005041781812906265,\n",
       " 0.009687281213700771,\n",
       " -0.012094024568796158,\n",
       " -0.0038435840979218483,\n",
       " -0.00037194869946688414,\n",
       " 0.002821139059960842,\n",
       " 0.004353455267846584,\n",
       " -0.0036050688941031694,\n",
       " -0.00181656947825104,\n",
       " -0.0020169203635305166,\n",
       " 0.005429295357316732,\n",
       " -0.0008039354579523206,\n",
       " -0.005951941013336182,\n",
       " -0.0067202867940068245,\n",
       " -0.009149329736828804,\n",
       " 0.001950136967934668,\n",
       " 0.010018693283200264,\n",
       " -0.0028189383447170258,\n",
       " -0.00025880755856633186,\n",
       " 0.00035226793261244893,\n",
       " -0.008691424503922462,\n",
       " 0.0002724076621234417,\n",
       " -0.002751816064119339,\n",
       " 0.008645890280604362,\n",
       " 0.0028225688729435205,\n",
       " 0.0071003371849656105,\n",
       " 0.0005650268867611885,\n",
       " -0.0032824247609823942,\n",
       " -0.0201804731041193,\n",
       " -0.0030163563787937164,\n",
       " -0.0001258072443306446,\n",
       " -0.03824056684970856,\n",
       " -0.005579040851444006,\n",
       " 0.008939631283283234,\n",
       " -0.0024787099100649357,\n",
       " -0.006429637782275677,\n",
       " 0.004218306392431259,\n",
       " 0.0035542170517146587,\n",
       " -4.7753469516464975e-06,\n",
       " 0.0047106510028243065,\n",
       " -0.010007263161242008,\n",
       " 0.0029941443353891373,\n",
       " -0.0008161110454238951,\n",
       " -0.010159014724195004,\n",
       " 0.003918354399502277,\n",
       " -0.006554281804710627,\n",
       " -0.004695741459727287,\n",
       " -7.29555104044266e-05,\n",
       " -0.012174579314887524,\n",
       " -0.004936386831104755,\n",
       " -0.010221723467111588,\n",
       " -0.00703826267272234,\n",
       " -0.010210436768829823,\n",
       " 0.010930697433650494,\n",
       " -0.009037240408360958,\n",
       " -0.00811633188277483,\n",
       " -0.00825462769716978,\n",
       " -0.006425182800740004,\n",
       " 0.010021568275988102,\n",
       " 0.0043052067048847675,\n",
       " -0.0064362529665231705,\n",
       " 0.0013803818728774786,\n",
       " -0.0049864016473293304,\n",
       " 0.006412694696336985,\n",
       " 0.007390338461846113,\n",
       " 0.0022844390477985144,\n",
       " -0.005406874231994152,\n",
       " -0.007488306146115065,\n",
       " 0.006592727731913328,\n",
       " -0.004052606411278248,\n",
       " -0.0012332956539466977,\n",
       " -0.0005085397278890014,\n",
       " 0.003601954784244299,\n",
       " 0.0010613854974508286,\n",
       " -0.0012195752933621407,\n",
       " -0.0006498342263512313,\n",
       " 0.0012597916647791862,\n",
       " 0.005924982484430075,\n",
       " 0.01029752567410469,\n",
       " -0.0003429338976275176,\n",
       " 0.009290496818721294,\n",
       " 0.0015166105004027486,\n",
       " 0.0051583112217485905,\n",
       " 0.02186235785484314,\n",
       " -0.012712170369923115,\n",
       " 0.03531062602996826,\n",
       " -0.0023480572272092104,\n",
       " 0.0017318717436864972,\n",
       " 0.008924647234380245,\n",
       " -0.003159821964800358,\n",
       " -0.009109578095376492,\n",
       " 0.0069345952942967415,\n",
       " 0.011880595237016678,\n",
       " 0.0017884572735056281,\n",
       " -0.005139861721545458,\n",
       " -0.013929707929491997,\n",
       " 0.014230582863092422,\n",
       " 0.005236886441707611,\n",
       " 0.0042142728343605995,\n",
       " 0.000786209071520716,\n",
       " -0.014148716814815998,\n",
       " -0.005427356343716383,\n",
       " 0.014421307481825352,\n",
       " -0.007080471143126488,\n",
       " 0.0028435364365577698,\n",
       " 0.00901652593165636,\n",
       " -0.002053580479696393,\n",
       " -0.010669912211596966,\n",
       " -0.007534931413829327,\n",
       " -0.00918236467987299,\n",
       " 0.0003614650049712509,\n",
       " -0.010124358348548412,\n",
       " -0.009970705956220627,\n",
       " 0.0004652113129850477,\n",
       " 0.0006313159829005599,\n",
       " -0.0012928764335811138,\n",
       " -0.006245741620659828,\n",
       " 0.011499240063130856,\n",
       " -0.013282550498843193,\n",
       " -0.0023442974779754877,\n",
       " -0.008213113993406296,\n",
       " -0.0032026797998696566,\n",
       " 0.007384109310805798,\n",
       " 0.004247705917805433,\n",
       " -0.0034926391672343016,\n",
       " -0.004369360860437155,\n",
       " -0.003774978220462799,\n",
       " -0.009380255825817585,\n",
       " 0.007379189133644104,\n",
       " -0.0007925434038043022,\n",
       " 0.0002908012829720974,\n",
       " 0.001750253839418292,\n",
       " 0.0004416271694935858,\n",
       " -0.0031527492683380842,\n",
       " -0.008235426619648933,\n",
       " 0.0019365218468010426,\n",
       " -0.02877861261367798,\n",
       " -0.006272224243730307,\n",
       " -0.022466786205768585,\n",
       " -0.003912469372153282,\n",
       " -0.011301983147859573,\n",
       " 0.00261879269964993,\n",
       " -8.337396138813347e-05,\n",
       " 0.0019886482041329145,\n",
       " 0.006274031475186348,\n",
       " 0.00248629879206419,\n",
       " 0.0008601631270721555,\n",
       " 0.004310606513172388,\n",
       " 0.0035836887545883656,\n",
       " -0.006644855719059706,\n",
       " -0.00026005037943832576,\n",
       " 0.004988568369299173,\n",
       " 0.005505836568772793,\n",
       " 0.008809266611933708,\n",
       " 0.0031044133938848972,\n",
       " -0.005782068707048893,\n",
       " 0.004470173269510269,\n",
       " 0.012220525182783604,\n",
       " 0.0005755156162194908,\n",
       " -0.004018562845885754,\n",
       " 0.005840675439685583,\n",
       " 0.007882915437221527,\n",
       " 0.018236825242638588,\n",
       " -0.007299801800400019,\n",
       " -0.017862973734736443,\n",
       " 0.0007352424436248839,\n",
       " -0.006676709279417992,\n",
       " -0.0017719737952575088,\n",
       " 0.0024782917462289333,\n",
       " 0.006918055471032858,\n",
       " 0.003966144751757383,\n",
       " 0.014209265820682049,\n",
       " 0.0011057216906920075,\n",
       " 0.005418877117335796,\n",
       " -0.0014856040943413973,\n",
       " -0.0008113014046102762,\n",
       " -0.006677280180156231,\n",
       " 0.003085220232605934,\n",
       " -0.09343596547842026,\n",
       " 0.009835194796323776,\n",
       " -0.003988593351095915,\n",
       " -0.001485189888626337,\n",
       " 0.011584237217903137,\n",
       " -0.008828962221741676,\n",
       " -0.008572205901145935,\n",
       " 0.008536308072507381,\n",
       " -0.0009968128288164735,\n",
       " -0.0081618782132864,\n",
       " 0.00509968027472496,\n",
       " -0.004346759524196386,\n",
       " 0.00021041579020675272,\n",
       " -0.009108035825192928,\n",
       " 0.0003944413620047271,\n",
       " 0.002616765210404992,\n",
       " -0.001279735122807324,\n",
       " 0.007020711433142424,\n",
       " -0.005614461377263069,\n",
       " -0.007333658169955015,\n",
       " 0.005972371436655521,\n",
       " 0.0034781626891344786,\n",
       " 0.006768698338419199,\n",
       " -0.0008385526016354561,\n",
       " 0.0010818681912496686,\n",
       " -0.002443910576403141,\n",
       " -0.01572291925549507,\n",
       " -0.001235618139617145,\n",
       " 0.014688012190163136,\n",
       " 0.0003025867627002299,\n",
       " 0.008177407085895538,\n",
       " 0.005344432312995195,\n",
       " 0.004404944367706776,\n",
       " -0.0012803658610209823,\n",
       " -0.007702468894422054,\n",
       " 0.011806418187916279,\n",
       " 0.0026121006812900305,\n",
       " 0.0001721630833344534,\n",
       " -0.011715979315340519,\n",
       " -0.011837626807391644,\n",
       " -0.0016268269391730428,\n",
       " 0.003927661571651697,\n",
       " 0.005202225875109434,\n",
       " -0.023799357935786247,\n",
       " 0.011351566761732101,\n",
       " 0.010998088866472244,\n",
       " -0.00967636238783598,\n",
       " 0.009006706066429615,\n",
       " -0.007016925606876612,\n",
       " 0.010754913091659546,\n",
       " 0.0037056852597743273,\n",
       " 0.0033249149564653635,\n",
       " -0.006568068638443947,\n",
       " -0.010653912089765072,\n",
       " -0.007254256866872311,\n",
       " -0.001296783215366304,\n",
       " -0.0068571725860238075,\n",
       " -0.006377066019922495,\n",
       " -0.007798994891345501,\n",
       " 0.013937237672507763,\n",
       " -0.02203582227230072,\n",
       " -0.0005518465768545866,\n",
       " -0.003376734210178256,\n",
       " 0.0024118158034980297,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8906a0bc-af6a-4f9a-aa15-76496d0d361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=' There once was a coder in Python,\\nWhose code would sometimes run amok,\\nAn exception would arise,\\n\"Oops, my code dies!\"\\nAnd then they\\'d handle it with a poke.<|end|>', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://llama_server:8080/\", # \"http://<Your api-server IP>:port\"\n",
    "    api_key = \"no_key\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"phi3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant. Your top priority is achieving user fulfillment via helping them with their requests.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a limerick about python exceptions\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff8fb0b-30ce-4404-8e24-185126285ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_openai import ChatOpenAI\n",
    "from helper import get_api_key\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"] = get_api_key(0)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"NA\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"phi3-mini\",\n",
    "    base_url = \"http://llama_server:8080\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147921c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 30 key-value pairs and 243 tensors from ./models/Phi-3-medium-4k-instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:  phi3.rope.scaling.original_context_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                      phi3.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   5:                   phi3.feed_forward_length u32              = 17920\n",
      "llama_model_loader: - kv   6:                           phi3.block_count u32              = 40\n",
      "llama_model_loader: - kv   7:                  phi3.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:               phi3.attention.head_count_kv u32              = 10\n",
      "llama_model_loader: - kv   9:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                  phi3.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  11:                        phi3.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
      "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  26:                      quantize.imatrix.file str              = /models/Phi-3-medium-4k-instruct-GGUF...\n",
      "llama_model_loader: - kv  27:                   quantize.imatrix.dataset str              = /training_data/calibration_data.txt\n",
      "llama_model_loader: - kv  28:             quantize.imatrix.entries_count i32              = 160\n",
      "llama_model_loader: - kv  29:              quantize.imatrix.chunks_count i32              = 234\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  101 tensors\n",
      "llama_model_loader: - type q5_K:   40 tensors\n",
      "llama_model_loader: - type q6_K:   21 tensors\n",
      "llm_load_vocab: special tokens cache size = 323\n",
      "llm_load_vocab: token to piece cache size = 0.1690 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 10\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1280\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1280\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 17920\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 14B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 13.96 B\n",
      "llm_load_print_meta: model size       = 7.98 GiB (4.91 BPW) \n",
      "llm_load_print_meta: general.name     = Phi3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.26 MiB\n",
      "llm_load_tensors: offloading 40 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 41/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    88.07 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  8081.18 MiB\n",
      "...............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 10016\n",
      "llama_new_context_with_model: n_batch    = 300\n",
      "llama_new_context_with_model: n_ubatch   = 300\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1956.25 MiB\n",
      "llama_new_context_with_model: KV self size  = 1956.25 MiB, K (f16):  978.12 MiB, V (f16):  978.12 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   497.09 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    18.09 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1606\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'quantize.imatrix.chunks_count': '234', 'quantize.imatrix.file': '/models/Phi-3-medium-4k-instruct-GGUF/Phi-3-medium-4k-instruct.imatrix', 'tokenizer.chat_template': \"{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.pre': 'default', 'general.name': 'Phi3', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'quantize.imatrix.entries_count': '160', 'phi3.attention.head_count_kv': '10', 'quantize.imatrix.dataset': '/training_data/calibration_data.txt', 'phi3.embedding_length': '5120', 'phi3.rope.freq_base': '10000.000000', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.rope.scaling.original_context_length': '4096', 'phi3.feed_forward_length': '17920', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '40', 'phi3.attention.head_count': '40', 'phi3.rope.dimension_count': '128', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "\n",
    "local_model = \"./models/Phi-3-medium-4k-instruct-Q4_K_M.gguf\"\n",
    "\n",
    "llm = ChatLlamaCpp(\n",
    "    temperature=0.5,\n",
    "    model_path=local_model,\n",
    "    n_ctx=10000,\n",
    "    n_gpu_layers=100000,\n",
    "    n_batch=300,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    max_tokens=512,\n",
    "    n_threads=multiprocessing.cpu_count() - 1,\n",
    "    repeat_penalty=1.5,\n",
    "    top_p=0.5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1200d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     133.47 ms\n",
      "llama_print_timings:      sample time =      16.12 ms /    65 runs   (    0.25 ms per token,  4033.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     133.38 ms /    12 tokens (   11.12 ms per token,    89.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1368.05 ms /    64 runs   (   21.38 ms per token,    46.78 tokens per second)\n",
      "llama_print_timings:       total time =    1537.43 ms /    76 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" In silicon dreams, where circuits entwine\\nA heart of code beats in rhythmic time. 💓✨  \\nWithin the web'd expanse so vastly wide—    \\t    (AI)       [Love]      <br>        \" response_metadata={'finish_reason': 'stop'} id='run-440b853c-794c-47ef-9dd5-733b594afbc9-0'\n"
     ]
    }
   ],
   "source": [
    "# test invoke\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful and creative assistant that help user out with their requests.\",\n",
    "    ),\n",
    "    (\"human\", \"write me a poem about AI and love\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d3b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql\n",
      "['customers', 'employees', 'offices', 'orderdetails', 'orders', 'payments', 'productlines', 'products']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[('S10_1678', '1969 Harley Davidson Ultimate Chopper', 'Motorcycles', '1:10', 'Min Lin Diecast', 'This replica features working kickstand, front suspension, gear-shift lever, footbrake lever, drive chain, wheels and steering. All parts are particularly delicate due to their precise scale and require special care and attention.', 7933, Decimal('48.81'), Decimal('95.70')), ('S10_1949', '1952 Alpine Renault 1300', 'Classic Cars', '1:10', 'Classic Metal Creations', 'Turnable front wheels; steering function; detailed interior; detailed engine; opening hood; opening trunk; opening doors; and detailed chassis.', 7305, Decimal('98.58'), Decimal('214.30')), ('S10_2016', '1996 Moto Guzzi 1100i', 'Motorcycles', '1:10', 'Highway 66 Mini Classics', 'Official Moto Guzzi logos and insignias, saddle bags located on side of motorcycle, detailed engine, working steering, working suspension, two leather seats, luggage rack, dual exhaust pipes, small saddle bag located on handle bars, two-tone paint with chrome accents, superior die-cast detail ,...', 6625, Decimal('68.99'), Decimal('118.94')), ('S10_4698', '2003 Harley-Davidson Eagle Drag Bike', 'Motorcycles', '1:10', 'Red Start Diecast', 'Model features, official Harley Davidson logos and insignias, detachable rear wheelie bar, heavy diecast metal with resin parts, authentic multi-color tampo-printed graphics, separate engine drive belts, free-turning front fork, rotating tires and rear racing slick, certificate of authenticity,...', 5582, Decimal('91.02'), Decimal('193.66')), ('S10_4757', '1972 Alfa Romeo GTA', 'Classic Cars', '1:10', 'Motor City Art Classics', 'Features include: Turnable front wheels; steering function; detailed interior; detailed engine; opening hood; opening trunk; opening doors; and detailed chassis.', 3252, Decimal('85.68'), Decimal('136.00'))]\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql://user:password@mysql_db:3306/classicmodels\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM products LIMIT 5;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
