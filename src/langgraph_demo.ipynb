{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 30 key-value pairs and 243 tensors from ./models/Phi-3-medium-4k-instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
      "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:  phi3.rope.scaling.original_context_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                      phi3.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   5:                   phi3.feed_forward_length u32              = 17920\n",
      "llama_model_loader: - kv   6:                           phi3.block_count u32              = 40\n",
      "llama_model_loader: - kv   7:                  phi3.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:               phi3.attention.head_count_kv u32              = 10\n",
      "llama_model_loader: - kv   9:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                  phi3.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  11:                        phi3.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% for message in messages %}{% if (m...\n",
      "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  26:                      quantize.imatrix.file str              = /models/Phi-3-medium-4k-instruct-GGUF...\n",
      "llama_model_loader: - kv  27:                   quantize.imatrix.dataset str              = /training_data/calibration_data.txt\n",
      "llama_model_loader: - kv  28:             quantize.imatrix.entries_count i32              = 160\n",
      "llama_model_loader: - kv  29:              quantize.imatrix.chunks_count i32              = 234\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  101 tensors\n",
      "llama_model_loader: - type q5_K:   40 tensors\n",
      "llama_model_loader: - type q6_K:   21 tensors\n",
      "llm_load_vocab: special tokens cache size = 323\n",
      "llm_load_vocab: token to piece cache size = 0.1690 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 10\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1280\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1280\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 17920\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 14B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 13.96 B\n",
      "llm_load_print_meta: model size       = 7.98 GiB (4.91 BPW) \n",
      "llm_load_print_meta: general.name     = Phi3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.26 MiB\n",
      "llm_load_tensors: offloading 40 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 41/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    88.07 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  8081.18 MiB\n",
      "...............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 10016\n",
      "llama_new_context_with_model: n_batch    = 3000\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1956.25 MiB\n",
      "llama_new_context_with_model: KV self size  = 1956.25 MiB, K (f16):  978.12 MiB, V (f16):  978.12 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   847.07 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    29.57 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1606\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'quantize.imatrix.chunks_count': '234', 'quantize.imatrix.file': '/models/Phi-3-medium-4k-instruct-GGUF/Phi-3-medium-4k-instruct.imatrix', 'tokenizer.chat_template': \"{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'tokenizer.ggml.pre': 'default', 'general.name': 'Phi3', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'quantize.imatrix.entries_count': '160', 'phi3.attention.head_count_kv': '10', 'quantize.imatrix.dataset': '/training_data/calibration_data.txt', 'phi3.embedding_length': '5120', 'phi3.rope.freq_base': '10000.000000', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.rope.scaling.original_context_length': '4096', 'phi3.feed_forward_length': '17920', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '40', 'phi3.attention.head_count': '40', 'phi3.rope.dimension_count': '128', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
      "' + message['content'] + '<|end|>' + '\n",
      "' + '<|assistant|>' + '\n",
      "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
      "'}}{% endif %}{% endfor %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "# this notebook will demo the basic useage of langgraph\n",
    "\n",
    "# it will first create llm instance which is connected to a locally host LLM\n",
    "import multiprocessing\n",
    "\n",
    "from langchain_community.chat_models import ChatLlamaCpp\n",
    "\n",
    "local_model = \"./models/Phi-3-medium-4k-instruct-Q4_K_M.gguf\"\n",
    "\n",
    "llm = ChatLlamaCpp(\n",
    "    temperature=0.5,\n",
    "    model_path=local_model,\n",
    "    n_ctx=10000,\n",
    "    n_gpu_layers=100000,\n",
    "    n_batch=3000,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    max_tokens=2048,\n",
    "    n_threads=multiprocessing.cpu_count() - 1,\n",
    "    repeat_penalty=1.5,\n",
    "    top_p=0.5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Messages have the type \"list\". The `add_messages` function\n",
    "    in the annotation defines how this state key should be updated\n",
    "    (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# a state graph object defines the structure of our chatbot as a \"state machine\"\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be called whenever the \"chatbot\" node is used\n",
    "# it takes the current state as input and returns the new state by invoking the LLM with the current state's messages\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\"\"\"\n",
    "The first argument is the unique node name\n",
    "The second argument is the function or object that will be called whenever\n",
    "the node is used.\n",
    "\"\"\"\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# add start and end edge to the graph connecting the node chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADbAGsDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAUGBAcIAwIJAf/EAFAQAAEDAwEDBAsNAwgLAAAAAAECAwQABREGBxIhCBYxQRMUFSJRVVZhlNHTFyMyN0JSVHF2gZGVtHWT0jVDU2J0krPECRgkJTM0Y4OxwcP/xAAaAQEBAAMBAQAAAAAAAAAAAAAAAQIDBAUH/8QAMREAAgADBQQIBwEAAAAAAAAAAAECAxEEEiExURNxobEUFSNSYYGR0QUiM0FTweHx/9oADAMBAAIRAxEAPwD9U6UqCu12lybgLRaQkSwkLkzHBvNxEHo4fKcV8lPQACpXDdSvOGFxuiLmTL8hqM2XHnENIHSpagkD7zUedU2UHBu8AH+0o9dYDOz+ylYeuEUXuZjCpV1AfWeOeAI3UfUhKR5qzhpWygY7jwMf2VHqrbSSs22MD+86rL44geko9dOdVl8cQPSUeunNWy+J4HoyPVTmrZfE8D0ZHqp2PjwLgOdVl8cQPSUeunOqy+OIHpKPXTmrZfE8D0ZHqpzVsvieB6Mj1U7Hx4DAc6rL44geko9dOdVl8cQPSUeunNWy+J4HoyPVTmrZfE8D0ZHqp2PjwGBkw7tBuBIizI8kjqZdSv8A8GsuoKZoTTk8e/WO3qV1OJjIStPnSoAEHzg1huomaLBfS/JuljB9+afV2R+Gn56FfCcQOkpUVKAyQTgJpcgjwgeOj9/8JRPItNK+W3EPNpcbUlaFAKSpJyCD0EGvquch5yH0RmHHnDhDaStR8AAyagNn7KjpiLcHgO3LqO6MhQzxW4AQOPzU7iB5kCpq5RO37dKi5x2dpbefBkEf+6itBSu29F2VZBS4iI204lQwUuIG4tJHmUkj7q6FhJdNV+y/YnqUpXOQruutoOn9mtjF31JcBboKnkRm1BpbrjrqzhDbbbaVLWo4OEpBPA+Ctb6y5U2mdMTtn6ozM+52nVUiU2Zke2TFuR0MtulRDKGFLUvsjYQUYCgN5RGEk1N8oW02i7aIiC72rUtwEe5MSYknSUdT1wt0hAUUSm0pye94g4Sr4eCkgmtRmdtBd09sf1vq3T16vEnT2oZ5mtQ7Z/vNcF2PJjx5LsRvJSshbZWhIyN7OBxAA3PrPlBaC2e3OPA1DfF2yQ9Hble+QJKm2WlkhC3lpbKWQSCMuFPQfBXvqfbnorR+pkaduV3d7uORGpzcCHAky3XGHFrQlxKWW17yctqyR8HAKsAgnQu3Mar2gXHWttl2jXr9quenGkaUtdiZejRXXno6+zd0FpKQlaXClJafUE7gOEqJNXDYpp+6J2uwL1NslxhMe5vZoHbM6E4zuSEvvl1glSRhxPeFSOkd6esUBcNlvKCtW0zW2r9NNQZ8KZZLo7BZW5AlBp9ttppSnFOqZS22recUA2VbxCQoZCga2vWj9k8i4aL2v7SNPXPT16SjUGoFXq33hqCty3LYVCYSQqQBuoWFMKTuqwSSnGc1vCgFKUoCsaGxBautkTgNWiYY0dKc4SwptDrSRnqSlwIHmRVnqs6ST2xetUz057E9cAy2SMZDTLbaj5+/Dg+6rNXRP+o3urvpjxK8xVXeCtG3KVLDal2Ka4XpHY0lSobxxvOED+aVjKiPgKyo5SpSkWila4I7tU8UwVXVGz3Rm1BiBJ1Bp+zaoZYSpUR2dFbkpQleN4oKgcBW6nOOnAqBHJt2UBJT7m+lt0kEjuSxgnq+T5zVlk6Ctbj7j8NUuzvOElarZJWwlRJySWwdwknjkpz08eJry5kyOrVN+H/eZ9lWy5KeUVN69qjA+NIbKNF7P5j8vTOlLPYJT7fYnXrbCbYWtGc7pKQMjIBxVrqr8yZHlVfv3zPsqcyZHlVfv3zPsqbOX3+DFFqWilc+7Yr1qHQm0TZRZLbqe6Kh6nvDsGcX1NKWG0slY3CGxunPWQa21zJkeVV+/fM+yps5ff4MUWpL6g07a9V2eTab1bo11tkkAPQ5jSXWnACFAKSoEHBAP1gVSUcm7ZS2SUbONLpJBGRaWBwIwR8HwGp/mTI8qr9++Z9lTmTI8qr9++Z9lTZy+/wYotSJtGwHZpYLpFuVt0DpyBcIriXmJUa2MocaWDkKSoJyCD1ip67X9yTJctNkW3Iuud1134TUFJ6Vu/1sfBb6VHHQneUnHOgmZHCbeb1PbPAtOTlNJV9fYtzI83Qeup63WyJaIiIsKM1EjpyQ2ygJGT0nh1nrPXTs4MU7z4DBHxZrTHsVqi2+KFBiOgISVneUrwqUetROST1kk1m0pWhtxOrzIKUpUApSlAKUpQHO/KW+Ojk9/aWR+mNdEVzvylvjo5Pf2lkfpjXRFAKUpQClKUApSlAKUpQClKUApSlAc78pb46OT39pZH6Y10RXO/KW+Ojk9/aWR+mNdEUApSlAKUpQClKUApSlAKVWrzqiW3cXbfZ4bMyUwEmQ7JeU0yySAQnISoqWUne3QBgYyRkZje7usPoFj9Le9nXVDZo4lXBb2i0LvWLdLXEvdsmW6ewiVBmMrjyGHBlLja0lKkkeAgkffVS7u6w+gWP0t72dO7usPoFj9Le9nWXRY9V6oUPxe5ROx2ZsL2v6g0lJSsxo7xdgPufz8RfFpecYJ3eCscApKh1V+rXId2NyNi3J9tECeFt3a8OKvU1hYILLjqEBLeD0FLbbYUPnb1Qe2bk8u7bte6J1Ve4FmRM02/vqaQ+4pM9kK30sO5a+AFjP1KWPlZG4+7usPoFj9Le9nToseq9UKF3pVI7u6w+gWP0t72dO7usPoFj9Le9nToseq9UKF3pVLTqrUNuSZFytUF6Ggbzvc+S4t5CeGVJQpsb+Bk4BB4cN44FW+NJamRmpDDiXWHUBxtxByFJIyCPMRWmZKil4xCh60pStJBSlKAoNhOb9q49fdbp8P+yx6m6g7B/L2rv2t/lY9a0vF81jtE2v6l0lp3U/My16YhQ3ZMpiAzKkzJEkOLSPfgpKW0pb44TvEk8RivWmOjW5ckVm227zAeuz1rbnRl3NhpD7sJLyS822oqCVqRnISSlQBIwSk+Csyua5+mdYXblEaliWXWncG5x9HWvti4t2tl5Up4PSwDuObyUIKt4qSATxAChjjivbZtS7QNCbOZNiv12tmrL1ZTc5Vn01ZIs5xwDdQX1qlKS2yyF7wwVBSioAHKTWm8Q6cW4hspClJSVndSCcZOM4H3A/hWLGvNvm3Gbb486M/PhBBlRWnkqdY3wSjfSDlO8ASM4yBwrlOZftRbZWuTfqJeoJOmbrdJE0PKt0aOtLb6YMgLdQl5tYyQhSd05ACzwyARYG9Nayu23Ha+rSutTp2dEiWdRL1uYkNzHRFc3ey7471HA57Hunvs54YqXtEDpivlTiEKQlSkpUs4SCcFRwTgfcCfurmvRG1vWXKAuGm4FkvQ0G2vSse/3CTGhNSnXpDzrjSWmw8FJS0CytROCo7yRkdNVZN71Ptd1dsTmv6nkafvbc2/2qTJtUWOtvs8VDra320vNrHviUDKTkAE4wRmre0B1/015bLiVbNdKk+K43+EmvRIKUgE7xA4k9deey34tNKfsuN/hJqzfoveuTL9i0UpSvOIKUpQFAsH8vau/a3+Vj1WNabFLbq3VSdSw75ftKX1UYQpE3T8tDKpbCSSlDqVoWlW6VKwrAUMnBq23GNJ0vfLnK7SkzrdcnkyeyQmi6th0NobUhSE98UkNpUFAHiVA7uE72NzzjeLL9+SS/ZV7Dgc1KKFVVFyRk03kR+ntmNu05qqRqBqbcZdwkWiJZnFTXw7vNR1OKQsqKd5ThLqt5RUc8OA45p8Dky2Gy27Tcaz6g1JZX7JazZkzYExtt+XD39/sTx7ERwUSQpAQoZOCK2BzzjeLL9+SS/ZU55xvFl+/JJfsqmwj7rF16FI/1cNOsaG07piDdb5bGtOzVzrRcokpAmQlLLmUJWpBCkbrq0YWlRKcZJIzXjeOTfbbvdLncBrDV1vk3aNHiXNUG4NtdvNstBpIc96yCRvEqRuqytWCBgC13Taxp+yTbdDuJuUCXcnSxCjybXJbclOAZKG0lsFagOOBk1Jc843iy/fkkv2VNhH3WLr0KlfdgNgnrsr1kuN40XLtFuFojytOyUsuGEMFLC+yIWFJBGQSN4Ekggk15zeTxplWltK2W1SrrpxWmXlv2y5WqUEy2luJUHipbiVhfZN9ZXvJOSeqrjzzjeLL9+SS/ZU55xvFl+/JJfsqbCPusXXoTUSOYkRlguuPltCUF14grXgY3lEAZJ6Twpst+LTSn7Ljf4SahucUm5ILNqs9zcmOZS2ZsF2Kyg/OWtxI70ZycAk4OATwq46es6NPWC22ttZdRCjNxw4U7u8EJCc4HRnHRWmf8ku7Fm2uFfcZIkKUpXnGIpSlAKUpQClKUBzvylvjo5Pf2lkfpjXRFc78pb46OT39pZH6Y10RQClKUApSlAKUpQClKUApSlAKUpQHO/KW+Ojk9/aWR+mNdEVzvylvjo5Pf2lkfpjXRFAKUpQClKUApSlAKUpQClK+FuobxvrSnPRvHFAfdYl3fmRbVNet8VE6e2wtceK492FLzgSSlBXuq3ATgb2DjOcHor27aZ/pm/wC8KdtM/wBM3/eFWjB+Wu1f/SFP601/oS6ytnC7PJ0XdnZjsF28Fan1FBbLRJjpLZB68K8GK7x5L23qTyjtmzurn9ML0q12+7DYjqmdtB9CEoJdSvsbfDeUtGMHi2ePUOGeXNyWp7/KOsUzScdK4u0CUG+8HvcedkB5SyB3qVJIdJP/AFT0Jr9G9m2i7Nsu0HYtKWdTaLfaYqIzZyAVkDvnFY+UpRUo+dRpRgtNK8u2mf6Zv+8K/okNKIAdQSegBQpRg9KUpUApSlAKxbpdItlt0idOeTHiMIK3HFdAA8w4k+ADiTwFZVag26Xlbs+zWNCsMFK58hPzikhLQ84yVq+tCa7LHZ+lT4ZWue4qK5qraLedWPuJakP2e1ZIbixl9jdcT1KccT3wJ+akgDODvYzVMVYba4pS3IEd1auKlutBalfWTxNZ9K+jyZUFnhuSlRGN5kfzetXiyH6Oj1U5vWrxZD9HR6qkKqF52uaS0/eXLXPvCGJTSkoePYXFNMKVjdS66lJQ2TkcFKHSK2RTVAqxRU8xV6k/zetXiyH6Oj1U5vWrxZD9HR6qrt82w6R05c51vuF2LMuApAloRFecEcKQlaVOKSghKClae/JCekZyCBl6o2maa0c/DZut0Sy/LQXWWmWnH1qbHS5utpUQj+scDz1jt4FX58s8RV6kvzetXiyH6Oj1UOnbUQR3Mh4PD/l0eqoLZPq6XrzZ3ZL/ADm2GpU5kuOIjJKWwd5Q70Ek9AHSTVtrKCZfhUSeDFXqe9kuVw0u4ldmnv28JI94SorYUPAWj3v3gA+Ait5bP9fM6zhrbeQmLdowHbEYHKSD0OIJ6UnH1g8D1E6GrLsV4c03qW0XVtW6GpCGHuPwmHFJQ4D4cZCseFAryrfYYLVLcSXzrJ/plTrgzpulKV89ArSG26KqPrW1Slf8OVAWyk4+U25vEZ+p0fgfBW76rO0HRqda2ExULSzOYWH4jy84Q4ARhWPkqBKT5jnpAr0vh9ohs1phjjyyfmVHP9K/kqM4xIk2+fGVHltZbfivDiP4knqI4EdFU33F9A+Rlj/L2v4a+hNxNJwUfn/GYFzrnKJotm3XTVFh1PY9Z3Lupd5L7Ttnly+58uNIXkFwNuJbQQFELCwOCeutte4voHyMsX5e1/DVySkISEpASkDAA6hWiOS51L6Sp580gabe0vNY92uO1bZRYmQWWYILK1dshNtS3hske+HeG7wzx4dNYGk1XPZ5qxm53PTt5uke7adtkVl+BCU+5EdYQoOMOJHFveKwrJwMg5PDhvSlToyqok6NVfq2/wBgoGwS2zLRsg0zDnxH4ExqOoORpLZbcbPZFHCkniDxq/1Xb9s60tqid27eNO2y6S9wN9nlxUOL3R0DJGccTUd7i2gfIyxfl7X8NbIIY5cKghSaWGf8Bc683oqri7Dgt8XZcpmOgAZ4qcSM/cMn6gajbFpmyaNhPM2i2wrNEWvsriIrSWUFWAN4gADOABnzVt3ZLoR96exqS4sqZaaSrtCO6khZKhul5QPR3uQkeBSiekVqtNphsslzI8/tvLDnU2/SlK+aFFKUoCF1JoyzauaQi6wUSFtght9JKHW89O64khSfuPGqU9sDtalEs329R0noQFsLA+oqaJ/Emtn0rslWy0SFdlxtLQtTVnuAwfKW9/hF9hT3AYPlLe/wi+wradK39Z2v8nL2FTVnuAwfKW9/hF9hT3AYPlLe/wAIvsK2nSnWdr/Jy9hU1Z7gMHylvf4RfYV/RsBgZ46kvZHm7VH/AMK2lSnWdr/JyFSlWDZBpywyG5KmHrpLbIUh+4udl3SOgpRgIB84SD56utKVxTZ0yc70yJt+IrUUpStJD//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helper import render_graph\n",
    "render_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  why does it rain on earth? can it happen on another planet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     128.62 ms\n",
      "llama_print_timings:      sample time =      50.46 ms /   215 runs   (    0.23 ms per token,  4261.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.56 ms /    17 tokens (    7.56 ms per token,   132.23 tokens per second)\n",
      "llama_print_timings:        eval time =    4594.84 ms /   214 runs   (   21.47 ms per token,    46.57 tokens per second)\n",
      "llama_print_timings:       total time =    4869.01 ms /   231 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  Rain is a part of the Earth's water cycle, which involves evaporation from bodies like oceans and lakes into clouds. When these tiny droplets in cloud combine to become heavier than air currents that carry them upward they fall back down as rain or other forms such snow if it’ s cold enough at ground level\n",
      " \tThe possibility of rainfall on another planet depends largely upon the presence and state (solid, liquid)of water. For instance: Mars has polar ice caps made from frozen carbon dioxide which sublimates directly into gas during warmer seasons but doesn't rain like Earth does due to lack sufficient atmospheric pressure or temperature for sustained stable bodies of surface liquids\n",
      " \tOn the other hand, Saturn’s moon Titan has a dense atmosphere and liquid hydrocarbon lakes that experience methane rainfall. This is an example where another celestial body experiences precipitation but with different materials than Earth' s water-based rain system\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # get user input\n",
    "    user_input = input(\"User: \")\n",
    "    # check for exit condition\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    # run the graph with the user input\n",
    "    print (\"User: \", user_input)\n",
    "    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "        # output the chatbot's response\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/Eiffel_Tower',\n",
       "  'content': 'Eiffel was similarly unworried, pointing out to a journalist that it was premature to judge the effect of the tower solely on the basis of the drawings, that the Champ de Mars was distant enough from the monuments mentioned in the protest for there to be little risk of the tower overwhelming them, and putting the aesthetic argument for the tower: \"Do not the laws of natural forces always conform to the secret laws of harmony?\"[17]\\nSome of the protesters changed their minds when the tower was built; others remained unconvinced.[18] Guy de Maupassant supposedly ate lunch in the tower\\'s restaurant every day because it was the one place in Paris where the tower was not visible.[19]\\nBy 1918, it had become a symbol of Paris and of France after Guillaume Apollinaire wrote a nationalist poem in the shape of the tower (a calligram) to express his feelings about the war against Germany.[20] The most recent, devised in 2004 after letters sent by Eiffel to the French Society of Civil Engineers in 1885 were translated into English, is described as a non-linear integral equation based on counteracting the wind pressure on any point of the tower with the tension between the construction elements at that point.[69]\\nThe Eiffel Tower sways by up to 9\\xa0cm (3.5\\xa0in) in the wind.[71]\\nFloors\\nThe four columns of the tower each house access stairs and elevators to the first two floors, while at the south column only the elevator to the second floor restaurant is publicly accessible.\\n A glass floor was installed on the first level during the 2014 refurbishment.[63]\\nDesign\\nMaterial\\nThe puddle iron (wrought iron) of the Eiffel Tower weighs 7,300 tonnes,[64] and the addition of lifts, shops and antennae have brought the total weight to approximately 10,100\\xa0tonnes.[65] As a demonstration of the economy of design, if the 7,300\\xa0tonnes of metal in the structure were melted down, it would fill the square base, 125 metres (410\\xa0ft) on each side, to a depth of only 6.25\\xa0cm (2.46\\xa0in) assuming the density of the metal to be 7.8\\xa0tonnes per cubic metre.[66] His aircraft became entangled in an aerial belonging to a wireless station.[43] A bust of Gustave Eiffel by Antoine Bourdelle was unveiled at the base of the north leg on 2 May 1929.[44] In 1930, the tower lost the title of the world\\'s tallest structure when the Chrysler Building in New York City was completed.[45] In 1938, the decorative arcade around the first level was removed.[46]\\nUpon the German occupation of Paris in 1940, the lift cables were cut by the French. The tower was an instant success with the public, and nearly 30,000 visitors made the 1,710-step climb to the top before the lifts entered service on 26 May.[29]\\nTickets cost 2 francs for the first level, 3 for the second, and 5 for the top, with half-price admission on Sundays,[30] and by the end of the exhibition there had been 1,896,987 visitors.[4]\\nAfter dark, the tower was lit by hundreds of gas lamps, and a beacon sent out three beams of red, white and blue light.'},\n",
       " {'url': 'https://www.britannica.com/topic/Eiffel-Tower-Paris-France',\n",
       "  'content': 'Because of their unique shape, which was dictated partly by engineering considerations but also partly by Eiffel’s artistic sense, the piers required elevators to ascend on a curve; the glass-cage machines designed by the Otis Elevator Company of the United States became one of the principal features of the building, helping establish it as one of the world’s premier tourist attractions.\\n Situated on the “Left Bank,” meaning it is to the south of the Seine River, the storied 7th arrondissement neighbourhood in Paris is home to many other famous tourist attractions, such as the Musée d’Orsay and the Rodin Museum.\\n The Eiffel Tower was the tallest structure in the world until the topping off of the Chrysler Building in New York City in 1929. When the French government was organizing the International Exposition of 1889 to celebrate the centenary of the French Revolution, a competition was held for designs for a suitable monument. When the French government was organizing the International Exposition of 1889 to celebrate the centenary of the French Revolution, a competition was held for designs for a suitable monument.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from helper import get_api_key\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# set the TAVILY_API_KEY environment variable to the API key\n",
    "os.environ[\"TAVILY_API_KEY\"] = get_api_key(1)\n",
    "\n",
    "# create a TavilySearchResults tool with a maximum of 2 results\n",
    "searchtool = TavilySearchResults(max_results=2)\n",
    "tools = [searchtool]\n",
    "# invoke the tool\n",
    "searchtool.invoke(\"How tall is the Eiffel Tower?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now bind the tools to the LLM instance\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# start a new graph builder and add the new chatbot node\n",
    "graph_builder_1 = StateGraph(State)\n",
    "\n",
    "def chatbot_1(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder_1.add_node(\"chatbot\", chatbot_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a basic tool node to demo tool calling\n",
    "import json\n",
    "from typing import Any\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    #A node that runs the tools requested in the last AI Message\n",
    "    def __init__(self, tools):\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "    \n",
    "    def __call__(self, inputs: dict):\n",
    "        # get the last message from the inputs, if not raise an error\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No messages in inputs\")\n",
    "        outputs =[]\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call.tool_name].invoke(tool_call[\"args\"])\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content = json.dumps(tool_result),\n",
    "                    name = tool_call[\"name\"],\n",
    "                    tool_call_id = tool_call[\"id\"]\n",
    "                )  \n",
    "            )\n",
    "        return {\"messages\": outputs} \n",
    "    \n",
    "# add the tools node to the graph\n",
    "tool_node = BasicToolNode(tools = tools)\n",
    "graph_builder_1.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create conditional edge which will call the tools node if the last message contains tool calls\n",
    "from typing import Literal\n",
    "\n",
    "def route_tools(state: State,) -> Literal[\"tools\", \"__end__\"]:\n",
    "    # get message from state, check for different types of state\n",
    "    if isinstance(state,list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    # check if the message contains tool calls\n",
    "    if hasattr(ai_message,\"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return \"__end__\"\n",
    "\n",
    "# add the conditional edge function to the graph\n",
    "graph_builder_1.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", \"__end__\": \"__end__\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add the rest of the edges\n",
    "graph_builder_1.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder_1.add_edge(START, \"chatbot\")\n",
    "# only use memory with the ToolNode\n",
    "graph = graph_builder_1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     137.11 ms\n",
      "llama_print_timings:      sample time =      35.58 ms /   147 runs   (    0.24 ms per token,  4132.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     137.05 ms /    14 tokens (    9.79 ms per token,   102.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3146.18 ms /   146 runs   (   21.55 ms per token,    46.41 tokens per second)\n",
      "llama_print_timings:       total time =    3380.24 ms /   160 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  The height of Gustave's tower, also known as La Tour de Fer or more commonly referred to by its English name \"The Iron Lady,\" has seen changes over time due primarily for maintenance and broadcasting purposes. Originally completed on March 31st during a year that marked the end-of an era in France - precisely one hundred years after Napoleon's coronation, it stood at approximately three times fifty meters tall when measured from its base to what was then considered as 'the tip.'\n",
      " However today The Iron Lady stands slightly taller due for broadcasting antennas. Including these additions the Eiffel Tower reaches a height of 324 metres (1063 feet).\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
